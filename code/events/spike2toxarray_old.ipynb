{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np,xarray as xr\n",
    "from pathlib import Path\n",
    "import re, yaml, copy, json\n",
    "import helper, events_methods\n",
    "from sonpy import lib as sp\n",
    "import subprocess\n",
    "import plotly\n",
    "from helper import RenderJSON\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"1MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "# itables.options.scrollY=\"200px\"\n",
    "# itables.options.scrollCollapse=True\n",
    "# itables.options.paging=False\n",
    "# itables.options.column_filters = \"footer\"\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "spike2_path = Path(params[\"smrx_path\"])\n",
    "info_path = Path(params[\"config_path\"])\n",
    "res_path = Path(params[\"dest_path\"])\n",
    "RenderJSON(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyFile = sp.SonFile(str(spike2_path), True)\n",
    "all_channels = pd.DataFrame([dict(\n",
    "    name=MyFile.GetChannelTitle(i), \n",
    "    id=i, \n",
    "    chan_type=str(MyFile.ChannelType(i))[len(\"DataType.\"):],\n",
    "    unit=MyFile.GetChannelUnits(i),\n",
    "    size=MyFile.ChannelBytes(i),\n",
    "    item_size=MyFile.ItemSize(i),\n",
    "    scale=MyFile.GetChannelScale(i)/6553.6,\n",
    "    offset=MyFile.GetChannelOffset(i),\n",
    "    divide = MyFile.ChannelDivide(i),\n",
    ")  for i in range(MyFile.MaxChannels()) if MyFile.ChannelType(i) != sp.DataType.Off])\n",
    "all_channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = yaml.safe_load(info_path.open(\"r\"))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {k+\"_channel\": grp[\"name\"].to_list() for k, grp in all_channels.groupby(\"chan_type\")}\n",
    "processing = events_methods.EventProcessing.process_info(channels_dict, info[\"processing\"] , dest_name=\"dest_channel\")\n",
    "processing_df = pd.DataFrame(list(processing.values()))\n",
    "processing_df [\"name\"] = processing_df[\"method_params\"].apply(lambda m: m[\"channel_name\"])\n",
    "processing_df  = processing_df.merge(all_channels, how=\"left\", on=\"name\")\n",
    "processing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dest_chan, item in channels_dict.items():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
