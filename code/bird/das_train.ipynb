{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import das.train \n",
    "from helper import RenderJSON\n",
    "import helper, config_adapter\n",
    "import pandas as pd, numpy as np,xarray as xr, yaml\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"1MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"./model\")\n",
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "RenderJSON(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(params[\"config_path\"])\n",
    "config = config_adapter.load(config_path)\n",
    "RenderJSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(params[\"annotation_path\"]).rename(columns={\"name\": \"label\", \"start_seconds\": \"start\", \"stop_seconds\": \"end\"}).sort_values(\"start\")\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = scipy.io.wavfile.read(params[\"audio_path\"])\n",
    "song = xr.Dataset()\n",
    "song[\"data\"] = xr.DataArray(data, dims=\"t\")\n",
    "song[\"t\"] = np.arange(data.size)/fs\n",
    "song[\"t\"].attrs[\"fs\"] = fs\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "song[\"label\"] = xr.DataArray(np.full(song[\"data\"].size, \"noise\", dtype=object), dims=\"t\")\n",
    "song[\"goal\"] = xr.DataArray(np.full(song[\"data\"].size, None, dtype=object), dims=\"t\")\n",
    "annotations[\"next_start\"] = annotations[\"start\"].shift(-1, fill_value=np.inf)\n",
    "annotations[\"prev_end\"] = annotations[\"end\"].shift(1, fill_value=-np.inf)\n",
    "for row in annotations.to_dict(orient=\"index\").values():\n",
    "    song[\"label\"] = xr.where((song[\"t\"] >= row[\"start\"]) & (song[\"t\"] < row[\"end\"]), row[\"label\"], song[\"label\"])\n",
    "    song[\"goal\"] = xr.where((song[\"t\"] >= (row[\"start\"] + row[\"prev_end\"])/2) & (song[\"t\"] <= (row[\"end\"] + row[\"next_start\"])/2), row[\"goal\"], song[\"goal\"])\n",
    "if song[\"goal\"].isnull().any():\n",
    "    raise Exception(\"null goal problem...\")\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_num = {l:i for i,l in enumerate([\"noise\"] + [l for l in annotations[\"label\"].drop_duplicates() if not l==\"noise\"])}\n",
    "num_to_labels = {i:l for l, i  in labels_to_num.items()}\n",
    "song[\"syb\"] = xr.DataArray(list(labels_to_num.keys()), dims=\"syb\")\n",
    "song[\"label_proba\"] = (song[\"label\"] == song[\"syb\"]).astype(int)\n",
    "display(song[\"label_proba\"].groupby(song[\"goal\"]).apply(lambda d: d.sum(\"t\")).unstack().to_dataframe()[\"label_proba\"].unstack(\"goal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goals = annotations[\"goal\"].drop_duplicates().tolist()\n",
    "datasets = {k: song.where(song[\"goal\"] == k, drop=True) for k in goals}\n",
    "all = {k: dict(x= datasets[k][\"data\"].to_numpy().reshape(-1, 1),y=datasets[k][\"label_proba\"].transpose(\"t\", \"syb\").to_numpy()) for k in datasets}\n",
    "attrs = dict(samplerate_x_Hz=fs, samplerate_y_Hz=fs, class_names=song[\"syb\"].to_numpy(), class_types=[\"segment\"]*song[\"syb\"].size)\n",
    "all[\"attrs\"] = attrs\n",
    "dataset_dir =Path(\"das_training_dataset.npy\")\n",
    "\n",
    "for folder in all:\n",
    "    if folder != \"attrs\":\n",
    "        (dataset_dir/folder).mkdir(exist_ok=True, parents=True)\n",
    "        for arr in all[folder]:\n",
    "            np.save(dataset_dir/folder/(arr + \".npy\"),  all[folder][arr])\n",
    "    else:\n",
    "        np.save(dataset_dir/\"attrs.npy\", all[\"attrs\"], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir.mkdir(exist_ok=True, parents=True)\n",
    "model, desc, o = das.train.train(data_dir = dataset_dir, save_dir=str(model_dir), **config[\"das_train_params\"], save_name=\"das\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import das.utils\n",
    "results = das.utils.load_params(str(model_dir /\"das\"))\n",
    "results[\"class_names\"] = list(results[\"class_names\"])\n",
    "results[\"data_dir\"] = str(results[\"data_dir\"].resolve())\n",
    "group_keys = {k:v for k, v in results.items() if not hasattr(v, \"__getitem__\") or isinstance(v, str)}\n",
    "results[\"other\"] = group_keys\n",
    "results = {k:v for k,v in results.items() if not k in group_keys.keys()}\n",
    "display(RenderJSON(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    confusion_matrix = pd.DataFrame(results[\"conf_mat\"])\n",
    "    if len(confusion_matrix.columns) != len(results[\"class_names\"]):\n",
    "        print(\"Confusion Matrix error due to mismatched lengths... Unknown problem probably originating from das\")\n",
    "    else:\n",
    "        confusion_matrix.columns=results[\"class_names\"]\n",
    "        confusion_matrix.index=results[\"class_names\"]\n",
    "        confusion_matrix= confusion_matrix.rename_axis(\"labeled\")\n",
    "        confusion_matrix= confusion_matrix.rename_axis(\"predicted\", axis=1)\n",
    "        display(confusion_matrix)\n",
    "except:\n",
    "    print(\"Problem with confusion matrix...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(results[\"report\"])\n",
    "report = report[[col for col in report.columns if not \"avg\" in col] + [col for col in report.columns if \"avg\" in col]]\n",
    "report = report.transpose().reset_index(names=\"syb\")\n",
    "accuracy = report[report[\"syb\"] == \"accuracy\"][\"f1-score\"].iat[0]\n",
    "display(f\"Model accuracy: {accuracy}\")\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "report = report[report[\"syb\"] != \"accuracy\"]\n",
    "report.set_index(\"syb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "das",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
