{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, xarray as xr\n",
    "from pathlib import Path\n",
    "import re, yaml, copy, json\n",
    "import helper, config_adapter\n",
    "from helper import RenderJSON\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "plotly_config = {'scrollZoom': True, 'displaylogo': False, 'toImageButtonOptions': {\n",
    "    'format': 'svg', # one of png, svg, jpeg, webp\n",
    "    'filename': 'custom_image',\n",
    "    'height': None,\n",
    "    'width': None,\n",
    "    'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "  },\n",
    "  'modeBarButtonsToAdd': \n",
    "    ['drawline',\n",
    "    'drawopenpath',\n",
    "    'drawclosedpath',\n",
    "    'drawcircle',\n",
    "    'drawrect',\n",
    "    'eraseshape'\n",
    "    ]\n",
    "  \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"1MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "RenderJSON(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(params[\"config_path\"])\n",
    "config = config_adapter.load(config_path)\n",
    "RenderJSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(params[\"annotation_path\"]).rename(columns={\"name\": \"label\", \"start_seconds\": \"start\", \"stop_seconds\": \"end\"}).sort_values(\"start\")\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, data = scipy.io.wavfile.read(params[\"audio_path\"])\n",
    "song = xr.Dataset()\n",
    "song[\"data\"] = xr.DataArray(data, dims=\"t\")\n",
    "song[\"t\"] = np.arange(data.size)/fs\n",
    "song[\"t\"].attrs[\"fs\"] = fs\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset()\n",
    "t_fs = config[\"processing\"][\"t_fs\"]\n",
    "ds[\"t\"] = xr.DataArray(np.arange(int(song[\"t\"].max()*t_fs)+1)/t_fs, dims=\"t\")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syb = annotations.to_xarray().rename_dims(dict(index=\"syb\"))\n",
    "syb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_start_index = xr.DataArray(np.searchsorted(syb[\"start\"], ds[\"t\"]) , dims=\"t\")\n",
    "prev_start = xr.where(next_start_index ==0, np.nan , syb[\"start\"].isel(syb=next_start_index-1))\n",
    "next_start = xr.where(next_start_index == syb.sizes[\"syb\"], np.nan, syb[\"start\"].isel(syb=xr.where(next_start_index == syb.sizes[\"syb\"], 0, next_start_index)))\n",
    "next_end_index = xr.DataArray(np.searchsorted(syb[\"end\"], ds[\"t\"]) , dims=\"t\")\n",
    "prev_end = xr.where(next_end_index ==0, np.nan, syb[\"end\"].isel(syb=next_end_index-1))\n",
    "next_end = xr.where(next_end_index == syb.sizes[\"syb\"], np.nan, syb[\"end\"].isel(syb=xr.where(next_end_index == syb.sizes[\"syb\"], 0, next_end_index)))\n",
    "ds[\"prev_start\"] = xr.DataArray(prev_start.to_numpy(), dims=\"t\")\n",
    "ds[\"prev_end\"] = xr.DataArray(prev_end.to_numpy(), dims=\"t\")\n",
    "ds[\"next_start\"] = xr.DataArray(next_start.to_numpy(), dims=\"t\")\n",
    "ds[\"next_end\"] = xr.DataArray(next_end.to_numpy(), dims=\"t\")\n",
    "is_in_syb = prev_start.fillna(-np.inf) > prev_end.fillna(0)\n",
    "ds[\"d_before\"] = xr.where(is_in_syb, prev_start - ds[\"t\"], ds[\"t\"] - prev_end)\n",
    "ds[\"d_after\"] = xr.where(is_in_syb, ds[\"t\"] - next_end, next_start - ds[\"t\"])\n",
    "ds[\"is_in_syb\"] = is_in_syb\n",
    "display(ds)\n",
    "as_df = ds.to_dataframe().reset_index()\n",
    "display(as_df.loc[(as_df[\"t\"] >= syb[\"start\"].isel(syb=0).item() - 0.01) & (as_df[\"t\"] <= syb[\"end\"].isel(syb=1).item() + 0.01)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_envellope(arr_name, window_duration, window_type):\n",
    "  if arr_name == \"source_signal\":\n",
    "    sig = song[\"data\"]\n",
    "  else:\n",
    "    sig = ds[arr_name]\n",
    "  sig_fs = sig[\"t\"].attrs[\"fs\"]\n",
    "  win_size = int(np.round(window_duration*sig_fs))\n",
    "  stride = int(sig_fs/t_fs)\n",
    "  if window_type == \"hanning\":\n",
    "    window = xr.DataArray(np.hanning(win_size), dims=\"window\")\n",
    "  else:\n",
    "    raise Exception(f'Unhandled windowtype {window_type}')\n",
    "  tmp = sig.rolling(t=win_size, center=True).construct(\"window\", stride = stride).dropna(dim=\"t\", how=\"any\")\n",
    "  vol = np.abs(tmp * window).mean(\"window\")\n",
    "  vol[\"t\"].attrs[\"fs\"] = sig_fs/stride\n",
    "  return vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_mean(arr_name, window_duration):\n",
    "  if arr_name == \"source_signal\":\n",
    "    sig = song[\"data\"]\n",
    "  else:\n",
    "    sig = ds[arr_name]\n",
    "  sig_fs = sig[\"t\"].attrs[\"fs\"]\n",
    "  win_size = int(np.round(window_duration*sig_fs))\n",
    "  ret = sig.rolling(t=win_size, center=True).construct(\"window\").dropna(dim=\"t\", how=\"any\").mean(\"window\")\n",
    "  ret[\"t\"].attrs[\"fs\"] = sig_fs\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in config[\"processing\"][\"data\"]:\n",
    "    name = d[\"name\"]\n",
    "    if d[\"method\"] == \"envellope\":\n",
    "        res = compute_envellope(**d[\"method_params\"])\n",
    "    elif d[\"method\"] == \"sliding_mean\":\n",
    "        res = sliding_mean(**d[\"method_params\"])\n",
    "    elif d[\"method\"] == \"pandas_eval\":\n",
    "        res = ds.eval(d[\"method_params\"][\"expr\"]).reset_coords(drop=True)\n",
    "    if \"t\" in res.dims and (\"fs\" not in res[\"t\"].attrs or res[\"t\"].attrs[\"fs\"] != t_fs):\n",
    "        res = res.interp(t=ds[\"t\"])\n",
    "        res[\"t\"].attrs[\"fs\"] = t_fs\n",
    "    ds[name] = res\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[\"next_label\"] = annotations[\"label\"].shift(-1, fill_value=\"$\")\n",
    "annotations[\"prev_label\"] = annotations[\"label\"].shift(1, fill_value=\"^\")\n",
    "annotations[\"next_start\"] = annotations[\"start\"].shift(-1, fill_value=np.inf)\n",
    "annotations[\"prev_end\"] = annotations[\"end\"].shift(1, fill_value=0)\n",
    "all_transitions = pd.Series([(row[\"prev_label\"], row[\"label\"]) for row in annotations.to_dict(orient=\"index\").values()]+[(annotations[\"label\"].iat[-1], \"$\")]).drop_duplicates()\n",
    "all_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_corrections = dict(\n",
    "    start={tuple(i[\"transition\"]): {k: v for k, v in i.items() if k!=\"transition\"} for i in config[\"processing\"][\"specific_corrections\"][\"start\"]},\n",
    "    end={tuple(i[\"transition\"]): {k: v for k, v in i.items() if k!=\"transition\"} for i in config[\"processing\"][\"specific_corrections\"][\"end\"]},\n",
    ")\n",
    "corrections = pd.DataFrame()\n",
    "corrections[\"transition\"] = all_transitions\n",
    "start_mapped = corrections[\"transition\"].map(specific_corrections[\"start\"])\n",
    "corrections[\"start_params\"] = np.where(start_mapped.isna(), config[\"processing\"][\"default_corrections\"][\"start\"], start_mapped)\n",
    "end_mapped = corrections[\"transition\"].map(specific_corrections[\"end\"])\n",
    "corrections[\"end_params\"] = np.where(end_mapped.isna(), config[\"processing\"][\"default_corrections\"][\"end\"], end_mapped)\n",
    "display(corrections)\n",
    "corrections = corrections.set_index(\"transition\").to_dict(orient=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_bounds(correction_params, syb_t, prev_t, next_t):\n",
    "    [corr_min, corr_max] = correction_params[\"correction_limits\"]\n",
    "    [min_bound, max_bound] = [max((prev_t+syb_t)/2+0.00001, syb_t+corr_min), min((next_t+syb_t)/2 -0.00001, syb_t+corr_max)]\n",
    "    arr = ds.sel(t=slice(min_bound, max_bound)).eval(correction_params[\"expr\"])\n",
    "    if correction_params[\"method\"]==\"first_all_true\":\n",
    "        return float(arr[\"t\"].where(~arr).max().fillna(min_bound))\n",
    "    if correction_params[\"method\"]==\"min\":\n",
    "        return float(arr[\"t\"].isel(t=arr.argmin(\"t\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bounds = dict(start=[], end=[])\n",
    "for row in annotations.to_dict(orient=\"index\").values():\n",
    "    label = row[\"label\"]\n",
    "    for which in [\"start\", \"end\"]:\n",
    "        syb_t = row[which]\n",
    "        prev_t = row[\"start\"] if which==\"end\" else row[f\"prev_end\"]\n",
    "        next_t = row[\"end\"] if which==\"start\" else row[f\"next_start\"]\n",
    "        transition = (row[\"prev_label\"], row[\"label\"]) if which==\"start\" else (row[\"label\"], row[\"next_label\"])\n",
    "        correction_params = corrections[transition][f'{which}_params']\n",
    "        new_bounds[which].append(compute_new_bounds(correction_params, syb_t, prev_t, next_t))\n",
    "annotations[\"new_start\"] = new_bounds[\"start\"]\n",
    "annotations[\"new_end\"] = new_bounds[\"end\"]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = annotations[\"new_end\"]>annotations[\"new_start\"].shift(-1)\n",
    "noverlap = overlaps.sum()\n",
    "if noverlap > 0:\n",
    "    display(annotations)\n",
    "    raise Exception(\"Overlap problem...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_annotations =annotations.rename(columns=dict(start=\"uncorrected_start\", end=\"uncorrected_end\", new_start=\"start_seconds\", new_end=\"stop_seconds\", label=\"name\"))\n",
    "out_annotations.to_csv(params[\"out_annotations\"], index=False)\n",
    "out_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"display\"]:\n",
    "  import plotly.graph_objects as go\n",
    "  from plotly.subplots import make_subplots\n",
    "  if \"t_limits\" in config[\"display\"] and config[\"display\"][\"t_limits\"]:\n",
    "    t_min = config[\"display\"][\"t_limits\"][\"min\"]\n",
    "    t_max = config[\"display\"][\"t_limits\"][\"max\"]\n",
    "  else:\n",
    "    t_min, t_max = (-np.inf, np.inf)\n",
    "  sigs= config[\"display\"][\"signals\"]\n",
    "  if config[\"display\"][\"show_spectrogram\"]:\n",
    "    sigs = dict(song_display_spectrogram=dict(dest=\"_spec\"), **sigs)\n",
    "    win_size = 512\n",
    "    stride = 128\n",
    "    spectro_window = song[\"data\"].sel(t=slice(t_min-0.2, t_max+0.2)).rolling(t=win_size, min_periods=win_size, center=True).construct(\"window_t\", stride=stride)\n",
    "    spectro_window = spectro_window * xr.DataArray(np.hanning(spectro_window.sizes[\"window_t\"]), dims=\"window_t\")\n",
    "    fft = xr.apply_ufunc(np.fft.rfft, spectro_window, input_core_dims=[[\"window_t\"]], output_core_dims=[[\"f\"]])\n",
    "    fft[\"f\"] = np.fft.rfftfreq(spectro_window.sizes[\"window_t\"], 1/fs)\n",
    "    fft = fft.sel(f=slice(2000, 8000))\n",
    "    psd = np.abs(fft)**2\n",
    "    display_psd = np.log10(psd)\n",
    "    nds=xr.Dataset()\n",
    "    nds[\"song_display_spectrogram\"] = np.maximum(display_psd, display_psd.max()/2)\n",
    "    for sig in ds:\n",
    "      if \"t\" in ds[sig].dims:\n",
    "        try:\n",
    "          nds[sig] = ds[sig].interp(t=nds[\"t\"])\n",
    "        except:\n",
    "          nds[sig] = ds[sig].sel(t=nds[\"t\"], method=\"nearest\")\n",
    "      else:\n",
    "        nds[sig] = ds[sig]\n",
    "  else:\n",
    "    nds = ds.sel(t=slice(t_min, t_max))\n",
    "  \n",
    "  sigs_info = pd.DataFrame()\n",
    "  sigs_info[\"sig_name\"] = list(sigs.keys())\n",
    "  sigs_info[\"subplot_name\"] = [i[\"dest\"] for i in sigs.values()]\n",
    "  sigs_info[\"sig_ndim\"] = sigs_info[\"sig_name\"].apply(lambda n: nds[n].ndim)\n",
    "  sigs_info[\"subplot_num\"] = sigs_info.groupby(\"subplot_name\").ngroup()\n",
    "\n",
    "  plots_info = sigs_info.groupby([\"subplot_name\", \"subplot_num\"])[\"sig_ndim\"].max().reset_index()\n",
    "  plots_info[\"subplot_height\"] = plots_info[\"sig_ndim\"]/plots_info[\"sig_ndim\"].sum()\n",
    "  plots_info=plots_info.sort_values(\"subplot_num\")\n",
    "\n",
    "\n",
    "  n_subplots = len(plots_info.index)\n",
    "  fig = make_subplots(rows=n_subplots, cols=1, row_heights=plots_info[\"subplot_height\"].to_list(), shared_xaxes=True)\n",
    "\n",
    "  for row in sigs_info.to_dict(orient=\"index\").values():\n",
    "    arr = nds[row[\"sig_name\"]]\n",
    "    if arr.dims == (\"t\",):\n",
    "      fig.add_trace(go.Scatter(x=arr[\"t\"].to_numpy(),y=arr.to_numpy(),showlegend=True,name=row[\"sig_name\"]), row=row[\"subplot_num\"]+1, col=1)\n",
    "    elif arr.ndim == 0:\n",
    "      fig.add_hline(y=float(arr), row=row[\"subplot_num\"]+1, col=1, label = dict(\n",
    "        text=row[\"sig_name\"],\n",
    "        ), line=dict(color=\"black\"), showlegend=True)\n",
    "    elif arr.ndim == 2:\n",
    "      other_dim = [d for d in arr.dims if not d==\"t\"][0]\n",
    "      fig.add_trace(go.Heatmap(x=arr[\"t\"].values, y=arr[other_dim].values, z= arr.transpose(other_dim, \"t\").values,\n",
    "                     name=row[\"sig_name\"],showlegend=False, showscale=False)\n",
    "        ,row=row[\"subplot_num\"]+1, col=1\n",
    "      )\n",
    "    else:\n",
    "      raise Exception(\"Not handled\")\n",
    "\n",
    "\n",
    "  fig.add_vrect(x0=0, x1=0,label = dict(text=\"corrected_labels\"),line=dict(color=\"MediumPurple\"), showlegend=True, row=1, col=1)\n",
    "  fig.add_vrect(x0=0, x1=0,label = dict(text=\"uncorrected_labels\"),line=dict(color=\"yellow\", dash=\"dot\"), showlegend=True, row=1, col=1)\n",
    "  \n",
    "  for i, row in enumerate(out_annotations.to_dict(orient=\"index\").values()):\n",
    "    fig.add_vrect(x0=row[\"start_seconds\"], x1=row[\"stop_seconds\"],\n",
    "      label = dict(\n",
    "      text=row[\"name\"],\n",
    "      textposition=\"top center\",\n",
    "      font=dict(size=20, family=\"Times New Roman\", color=\"MediumPurple\"),\n",
    "      ),\n",
    "      line=dict(color=\"MediumPurple\"))\n",
    "    fig.add_vrect(x0=row[\"uncorrected_start\"], x1=row[\"uncorrected_end\"], line=dict(color=\"yellow\", dash=\"dot\"))\n",
    "\n",
    "  fig.update_layout(hovermode='x unified', hoversubplots=\"axis\", xaxis_showticklabels=True)\n",
    "  fig.show(config = plotly_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbscripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
