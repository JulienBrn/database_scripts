{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, zipfile\n",
    "import pandas as pd, numpy as np,xarray as xr, plotly\n",
    "from pathlib import Path\n",
    "import re, yaml, copy, json\n",
    "import helper, config_adapter\n",
    "from helper import RenderJSON\n",
    "plotly.offline.init_notebook_mode()\n",
    "plotly_config = {'scrollZoom': True, 'displaylogo': False, 'toImageButtonOptions': {\n",
    "    'format': 'svg', # one of png, svg, jpeg, webp\n",
    "    'filename': 'custom_image',\n",
    "    'height': None,\n",
    "    'width': None,\n",
    "    'scale': 1 # Multiply title/legend/axis/canvas sizes by this factor\n",
    "  },\n",
    "  'modeBarButtonsToAdd': \n",
    "    ['drawline',\n",
    "    'drawopenpath',\n",
    "    'drawclosedpath',\n",
    "    'drawcircle',\n",
    "    'drawrect',\n",
    "    'eraseshape'\n",
    "    ]\n",
    "  \n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"1MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "config_path = Path(params[\"config_path\"])\n",
    "if \"variables\" in params:\n",
    "    variables = config_adapter.normalize_yaml_paramlist(params[\"variables\"], format=config_adapter.variable_param_format)\n",
    "else: \n",
    "    variables = []\n",
    "RenderJSON(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = config_adapter.load(config_path)\n",
    "RenderJSON(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"variables\" in config:\n",
    "    variables += config_adapter.normalize_yaml_paramlist(config[\"variables\"], format=config_adapter.variable_param_format)\n",
    "display(RenderJSON(variables))\n",
    "ctx = config_adapter.Context()\n",
    "for var in variables:\n",
    "    config_adapter.add_variable_context(ctx, var)\n",
    "RenderJSON(ctx.variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "if \"random_seed\" in config:\n",
    "    random.seed(ctx.evaluate(config[\"random_seed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_koe_link(ctx, params):\n",
    "    params = ctx.evaluate(params)\n",
    "    zip_path = Path(params[\"download_path\"])\n",
    "    zip_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    if not zip_path.exists() or params[\"force_download\"]:\n",
    "        urllib.request.urlretrieve(params[\"link\"], zip_path)\n",
    "    zip = zipfile.Path(zip_path)\n",
    "    audio_folder = Path(params[\"audio_folder\"])\n",
    "    # display(RenderJSON([str(s) for s in zip.iterdir()]))\n",
    "    labels = zip / \"segment.extraattrvalue.json\"\n",
    "    with labels.open(\"r\") as f:\n",
    "        labels = json.load(f)\n",
    "    labels = pd.DataFrame(labels, columns=[\"id\", \"?\", \"label\"])[[\"id\", \"label\"]]\n",
    "    # display(labels)\n",
    "    timestamps = zip / \"songinfo.json\"\n",
    "    with timestamps.open(\"r\") as f:\n",
    "        timestamps = json.load(f)\n",
    "    all = []\n",
    "    for f, k in timestamps.items():\n",
    "        all.append(pd.DataFrame(k[1], columns=[\"id\", \"start\", \"end\", \"?1\", \"?2\", \"?3\", \"?id2\"]).assign(file=f)[[\"id\", \"file\", \"start\", \"end\"]])\n",
    "    timestamps = pd.concat(all)\n",
    "    timestamps[[\"start\", \"end\"]] = timestamps[[\"start\", \"end\"]] /1000\n",
    "    # display(timestamps)\n",
    "    annotations = pd.merge(timestamps, labels, on=\"id\", how=\"outer\").drop(columns=\"id\")\n",
    "    # display(annotations)\n",
    "    def find_audio(file):\n",
    "        r = list(audio_folder.glob(f\"**/{file}.*\"))\n",
    "        if len(r) == 0:\n",
    "            return None\n",
    "        if len(r) > 1:\n",
    "            raise Exception(\"Multiple matching files\")\n",
    "        return r[0]\n",
    "    annotations[\"audio_path\"] = annotations[\"file\"].apply(find_audio)\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctx.methods[\"from_koe_link\"] = from_koe_link\n",
    "annotations = ctx.evaluate(config[\"processing\"][\"annotations\"]).sort_values([\"audio_path\", \"start\"])\n",
    "del ctx.methods[\"from_koe_link\"]\n",
    "display(annotations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling of corrections todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_blocks(ctx, params):\n",
    "    global annotations\n",
    "    params = ctx.evaluate(params)\n",
    "    block_shoulder_duration = params[\"block_shoulder_duration\"]\n",
    "    annotations = annotations.copy()\n",
    "    annotations[\"block_change\"] = (annotations[\"file\"] != annotations[\"file\"].shift(1)) | ((annotations[\"start\"] - 2*block_shoulder_duration) > annotations[\"end\"].shift(1))\n",
    "    annotations[\"block\"] = annotations[\"block_change\"].cumsum()\n",
    "    annotations = annotations.drop(columns=\"block_change\")\n",
    "    groups = [df for _, df in annotations.groupby('block')]\n",
    "    random.shuffle(groups)\n",
    "    shuffled: pd.DataFrame = pd.concat(groups).reset_index(drop=True)\n",
    "    ars=[]\n",
    "    t_prev=0\n",
    "    new_t_start = []\n",
    "    new_t_end = []\n",
    "    common_fs = None\n",
    "    for i, row in shuffled.to_dict(orient=\"index\").items():\n",
    "        import scipy.io.wavfile\n",
    "        fs, data = scipy.io.wavfile.read(row[\"audio_path\"], mmap=True)\n",
    "        if common_fs is None:\n",
    "            common_fs = fs\n",
    "        elif fs!=common_fs:\n",
    "            raise Exception(\"Not same fs\")\n",
    "        ar = xr.Dataset()\n",
    "        istart = int((row[\"start\"]-block_shoulder_duration)*fs)\n",
    "        iend = int((row[\"end\"]+block_shoulder_duration)*fs)\n",
    "        ar[\"data\"] = xr.DataArray(data[istart: iend], dims=\"t\")\n",
    "        ar[\"t\"] = np.arange(ar[\"data\"].size)/fs + t_prev\n",
    "        ar[\"file\"] = row[\"audio_path\"]\n",
    "        ar[\"t_file\"] = xr.DataArray(np.arange(ar[\"data\"].size)/fs + (row[\"start\"]-block_shoulder_duration), dims=\"t\")\n",
    "        ar[\"block\"] = row[\"block\"]\n",
    "        ar[\"label\"] = xr.where((ar[\"t_file\"] >= row[\"start\"]) & (ar[\"t_file\"] <= row[\"end\"]), row[\"label\"], \"noise\")\n",
    "        ar[\"syb_num\"] = i\n",
    "        new_t_start.append(t_prev+block_shoulder_duration)\n",
    "        t_prev += ar[\"data\"].size/fs\n",
    "        new_t_end.append(t_prev-block_shoulder_duration)\n",
    "        ars.append(ar)\n",
    "    data: xr.Dataset = xr.concat(ars, dim=\"t\")\n",
    "    data[\"t\"].attrs[\"fs\"] = common_fs\n",
    "    shuffled[\"new_t_start\"] = new_t_start\n",
    "    shuffled[\"new_t_end\"] = new_t_end\n",
    "    shuffled[\"syb_num\"] = np.arange(len(shuffled.index))\n",
    "    return data, shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctx.methods[\"blocks\"] = mk_blocks\n",
    "merge_data, df = ctx.evaluate(config[\"processing\"][\"merge_data\"])\n",
    "fs = merge_data[\"t\"].attrs[\"fs\"]\n",
    "del ctx.methods[\"blocks\"]\n",
    "display(merge_data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_split(ctx, params):\n",
    "    params = ctx.evaluate(params)\n",
    "    max_syb = len(annotations.index)\n",
    "    if np.abs(np.sum(list(params.values())) -1) > 10**(-5):\n",
    "        raise Exception(\"problem sum!=1\")\n",
    "    merge_data[\"goal\"] = xr.DataArray(np.full(merge_data.sizes[\"t\"], \"none\", dtype=object), dims=\"t\")\n",
    "    df[\"goal\"] = \"none\"\n",
    "    cur=0\n",
    "    for k,v in params.items():\n",
    "        n = cur+ max_syb*v\n",
    "        df[\"goal\"] = np.where((df[\"syb_num\"] >=cur) & (df[\"syb_num\"] < n), str(k), df[\"goal\"])\n",
    "        merge_data[\"goal\"] = xr.where((merge_data[\"syb_num\"] >=cur) & (merge_data[\"syb_num\"] < n), str(k), merge_data[\"goal\"])\n",
    "        cur=n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.methods[\"percent_split\"] = percent_split\n",
    "ctx.evaluate(config[\"processing\"][\"split_data\"])\n",
    "del ctx.methods[\"percent_split\"]\n",
    "display(merge_data)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.groupby([\"goal\", \"label\"]).size().unstack(\"goal\").fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby([\"label\"]).apply(lambda d: \n",
    "                                    pd.Series(dict(\n",
    "                                        duration_mean=(d[\"end\"] - d[\"start\"]).mean(),\n",
    "                                        duration_std=(d[\"end\"] - d[\"start\"]).std(),\n",
    "                                        duration_min=(d[\"end\"] - d[\"start\"]).min(),\n",
    "                                        duration_max=(d[\"end\"] - d[\"start\"]).max(),\n",
    "                                    ))\n",
    ", include_groups=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_data = merge_data.set_coords([c for c in merge_data.data_vars if not c==\"data\"]).rolling(\n",
    "    t=512, min_periods=512, center=True).construct(\"window_t\", stride=128)\n",
    "\n",
    "spectrogram_data[\"windowed\"] = spectrogram_data[\"data\"] * xr.DataArray(np.hanning(512), dims=\"window_t\")\n",
    "spectrogram_data[\"fft\"]= xr.apply_ufunc(np.fft.rfft, spectrogram_data[\"windowed\"], input_core_dims=[[\"window_t\"]], output_core_dims=[[\"f\"]])\n",
    "spectrogram_data[\"psd\"] = np.abs(spectrogram_data[\"fft\"])**2\n",
    "spectrogram_data[\"f\"] = np.fft.rfftfreq(512, 1/fs)\n",
    "spectrogram_data[\"display_psd\"] = np.log(spectrogram_data[\"psd\"])\n",
    "spectrogram_data = spectrogram_data.sel(f=slice(200, 8000))\n",
    "display(spectrogram_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "max = spectrogram_data[\"display_psd\"].max().item()\n",
    "fig.add_trace(go.Heatmap(\n",
    "    z=spectrogram_data[\"display_psd\"].transpose(\"f\", \"t\").values, \n",
    "    x=spectrogram_data[\"t\"].values, \n",
    "    y=spectrogram_data[\"f\"].values,\n",
    "    hovertemplate =\"\"\"\n",
    "          <b>t: %{x}s</b>\n",
    "          f: %{y}Hz\n",
    "          val: %{z} (log10(fft**2))\n",
    "        \"\"\".replace('\\n', '<br>'),\n",
    "    zmin=max/2, zmax=max, name=\"spectrogram\"))\n",
    "min_t = spectrogram_data[\"t\"].min().item()\n",
    "max_t = spectrogram_data[\"t\"].max().item()\n",
    "fig.add_trace(go.Scatter(\n",
    "        x=spectrogram_data[\"t\"].values,\n",
    "        y=spectrogram_data[\"f\"].isel(f=10).item()*np.ones(spectrogram_data.sizes[\"t\"]),\n",
    "        customdata= spectrogram_data.assign(src_file=spectrogram_data[\"file\"].astype(str)).reset_coords([\"label\", \"t_file\", \"goal\", \"block\"])[[\"label\", \"src_file\", \"t_file\", \"goal\", \"block\"]].reset_coords(drop=True).to_dataframe(),\n",
    "        mode='lines',\n",
    "        opacity=0,\n",
    "        hovertemplate =\"\"\"\n",
    "          <b>syb_label: %{customdata[0]}</b>\n",
    "          src_file: %{customdata[1]}\n",
    "          t_file: %{customdata[2]}s\n",
    "          block_num: %{customdata[4]}\n",
    "          goal: %{customdata[3]}\n",
    "        \"\"\".replace('\\n', '<br>'),\n",
    "        showlegend=False,\n",
    "        name=\"info\"\n",
    "))\n",
    "for _, row in df.to_dict(orient=\"index\").items():\n",
    "    fig.add_vrect(x0=row[\"new_t_start\"], x1=row[\"new_t_end\"], \n",
    "                label = dict(\n",
    "                    text=row[\"label\"],\n",
    "                    textposition=\"top center\",\n",
    "                    font=dict(size=20, family=\"Times New Roman\", color=\"white\"),\n",
    "                ),\n",
    "                line=dict(color=\"MediumPurple\"))\n",
    "fig.update_layout(hovermode='x unified')\n",
    "fig.show(config = plotly_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_das(ctx, params):\n",
    "    params = ctx.evaluate(params)\n",
    "    global merge_data\n",
    "    labels = df[\"label\"].drop_duplicates()\n",
    "    if \"noise\" in labels:\n",
    "        merge_data[\"syb\"] = xr.DataArray([\"noise\"] +[l for l in labels if l!=\"noise\"], dims=\"syb\")\n",
    "    else:\n",
    "        merge_data[\"syb\"] = xr.DataArray(labels, dims=\"syb\")\n",
    "    merge_data[\"label_proba\"] = merge_data[\"label\"] == merge_data[\"syb\"]\n",
    "    merge_data = merge_data.transpose(\"t\", \"syb\")\n",
    "\n",
    "\n",
    "    goals = df[\"goal\"].drop_duplicates().tolist()\n",
    "    datasets = {k: merge_data.where(merge_data[\"goal\"] == k, drop=True) for k in goals}\n",
    "    all = {k: dict(x= datasets[k][\"data\"].to_numpy().reshape(-1, 1),y=datasets[k][\"label_proba\"].to_numpy()) for k in datasets}\n",
    "    attrs = dict(samplerate_x_Hz=fs, samplerate_y_Hz=fs, class_names=merge_data[\"syb\"].to_numpy(), class_types=[\"segment\"]*merge_data[\"syb\"].size)\n",
    "    all[\"attrs\"] = attrs\n",
    "    dir = Path(params[\"dest_folder\"])\n",
    "\n",
    "    for folder in all:\n",
    "        if folder != \"attrs\":\n",
    "            (dir/folder).mkdir(exist_ok=True, parents=True)\n",
    "            for arr in all[folder]:\n",
    "                np.save(dir/folder/(arr + \".npy\"),  all[folder][arr])\n",
    "        else:\n",
    "            np.save(dir/\"attrs.npy\", all[\"attrs\"], allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.methods[\"das_export\"] = export_das\n",
    "if not isinstance(config[\"processing\"][\"exports\"], list):\n",
    "    config[\"processing\"][\"exports\"] = [config[\"processing\"][\"exports\"]]\n",
    "for item in config[\"processing\"][\"exports\"]:\n",
    "    ctx.evaluate(item)\n",
    "del ctx.methods[\"das_export\"]\n",
    "display(merge_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbscripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
