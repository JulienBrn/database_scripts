{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np,xarray as xr\n",
    "from pathlib import Path\n",
    "import re, yaml, copy, json\n",
    "from helper import singleglob, json_merge\n",
    "import events_methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"1MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "# itables.options.scrollY=\"200px\"\n",
    "# itables.options.scrollCollapse=True\n",
    "# itables.options.paging=False\n",
    "# itables.options.column_filters = \"footer\"\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "dat_path = Path(params[\"dat_path\"])\n",
    "task_path = Path(params[\"task_path\"])\n",
    "info_path = Path(params[\"config_path\"])\n",
    "res_events_path = Path(params[\"dest_path\"])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading poly events and adding task information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.read_csv(dat_path, sep=\"\\t\", names=['time (ms)', 'family', 'nbre', '_P', '_V', '_L', '_R', '_T', '_W', '_X', '_Y', '_Z'], skiprows=13, dtype=int)\n",
    "event_df.insert(0, \"t\", event_df.pop(\"time (ms)\")/1000)\n",
    "event_df = event_df.reset_index(names=\"poly_evnum\").sort_values([\"t\", \"poly_evnum\"]).reset_index(drop=True)\n",
    "event_df[\"task_node\"] = event_df[\"_T\"].where(event_df[\"family\"]==10).ffill()\n",
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df = pd.read_csv(task_path, sep=\"\\t\", header=11)\n",
    "task_df = task_df.rename(columns={task_df.columns[0]: \"task_node\" })\n",
    "display(task_df.columns)\n",
    "task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "channels = pd.Series(task_df.columns).str.extract(r'\\s*(?P<channel_name>\\w+)\\s*\\((?P<family>\\d+)\\s*,\\s*(?P<nbre>\\d+)\\)\\s*').assign(taskcol_name=task_df.columns).dropna(how=\"any\")\n",
    "channels[\"family\"] = channels[\"family\"].astype(int)\n",
    "channels[\"nbre\"] = channels[\"nbre\"].astype(int)\n",
    "channels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=r'on\\(\\d+(,\\d+)*\\)'\n",
    "task_info=pd.DataFrame()\n",
    "stacked = task_df.set_index(\"task_node\")[channels[\"taskcol_name\"].to_list()].stack().str.lower().str.strip().dropna()\n",
    "stacked.index.names=[\"task_node\", \"taskcol_name\"]\n",
    "task_info[\"data\"] = stacked\n",
    "task_info[\"match\"] = task_info[\"data\"].str.fullmatch(pattern)\n",
    "task_info = task_info.loc[task_info[\"match\"]]\n",
    "task_info[\"important\"] = task_info[\"data\"].str.slice(3, -1)\n",
    "task_info[\"task_params\"] = task_info[\"important\"].str.split(\",\").apply(lambda l: [float(x) for x in l])\n",
    "task_info = task_info.drop(columns=[\"important\", \"match\", \"data\"]).join(stacked.rename(\"task_data\"), how=\"outer\")\n",
    "task_info = task_info.reset_index() \n",
    "task_info[\"task_node\"] = task_info[\"task_node\"].astype(float)\n",
    "task_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_channels_df = channels.merge(event_df, on=[\"family\", \"nbre\"], how=\"right\").merge(task_info, on=[\"taskcol_name\", \"task_node\"], how=\"left\").sort_values(\"t\")\n",
    "event_channels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting configuration information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = yaml.safe_load(info_path.open(\"r\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_spec = events_methods.FiberEventProcessing.process_info(channels[\"channel_name\"].to_list(), info[\"processing\"])\n",
    "pd.DataFrame(list(event_spec.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running event extraction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_channels_df = event_channels_df.sort_values([\"t\", \"poly_evnum\"])\n",
    "all=[]\n",
    "for ev_name, item in event_spec.items():\n",
    "    ev_dataframe = events_methods.PolyEventProcessing.compute_evdataframe(event_channels_df, item)\n",
    "    if len(ev_dataframe.index) == 0: continue\n",
    "    events = events_methods.PolyEventProcessing.call(item[\"method\"],ev_dataframe, item)\n",
    "    all.append(events.reset_index(drop=True))\n",
    "\n",
    "all = pd.concat(all).sort_values(\"t\")\n",
    "all\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming and exporting, displaying reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"display\" in info and \"rename\" in info[\"display\"]:\n",
    "    all[\"event_name\"] = all[\"event_name\"].map(lambda e: info[\"display\"][\"rename\"][e] if e in info[\"display\"][\"rename\"] else e)\n",
    "json_cols = [\"metadata\", \"waveform_changes\", \"waveform_values\"]\n",
    "for col in json_cols:\n",
    "    all[f\"{col}_json\"] = all[col].apply(lambda d: json.dumps(d))\n",
    "all.drop(columns=json_cols).to_csv(res_events_path, sep=\"\\t\", index=False)\n",
    "reloaded = pd.read_csv(res_events_path, sep=\"\\t\", index_col=False)\n",
    "for col in reloaded.columns:\n",
    "    if col.endswith(\"_json\"):\n",
    "        reloaded[col[:-5]] = reloaded.pop(col).apply(lambda s: json.loads(s) if not pd.isna(s) else None)\n",
    "reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Information (Checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = events_methods.EventProcessing.summarize(reloaded)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
