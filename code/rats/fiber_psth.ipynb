{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:29:57.098669Z",
     "iopub.status.busy": "2024-12-05T13:29:57.098293Z",
     "iopub.status.idle": "2024-12-05T13:29:57.334249Z",
     "shell.execute_reply": "2024-12-05T13:29:57.333867Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, xarray as xr\n",
    "from pathlib import Path\n",
    "import re, yaml, copy, json\n",
    "import helper, config_adapter\n",
    "from helper import RenderJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:29:57.336081Z",
     "iopub.status.busy": "2024-12-05T13:29:57.335871Z",
     "iopub.status.idle": "2024-12-05T13:29:57.582168Z",
     "shell.execute_reply": "2024-12-05T13:29:57.581660Z"
    }
   },
   "outputs": [],
   "source": [
    "import itables\n",
    "itables.init_notebook_mode(all_interactive=True )\n",
    "itables.options.maxBytes = \"10MB\"\n",
    "itables.options.lengthMenu = [25, 10, 50, 100, 200]\n",
    "itables.options.buttons = [\"copyHtml5\", \"csvHtml5\", \"excelHtml5\"]\n",
    "itables.options.layout={\"topEnd\": \"pageLength\", \"top1\": \"searchBuilder\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:29:57.591130Z",
     "iopub.status.busy": "2024-12-05T13:29:57.590588Z",
     "iopub.status.idle": "2024-12-05T13:29:57.595567Z",
     "shell.execute_reply": "2024-12-05T13:29:57.595093Z"
    }
   },
   "outputs": [],
   "source": [
    "params = yaml.safe_load(Path(\"params.yaml\").open(\"r\"))\n",
    "RenderJSON(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:29:57.597461Z",
     "iopub.status.busy": "2024-12-05T13:29:57.597135Z",
     "iopub.status.idle": "2024-12-05T13:29:57.628005Z",
     "shell.execute_reply": "2024-12-05T13:29:57.627581Z"
    }
   },
   "outputs": [],
   "source": [
    "config_path = Path(params[\"config_path\"])\n",
    "config = config_adapter.load(config_path)\n",
    "RenderJSON(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling of Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(params[\"fiber_event_path\"], sep=\",\").rename(columns=dict(Name=\"channel_name\")).reset_index(names=\"original_index\").sort_values([\"TimeStamp\", \"original_index\"])\n",
    "events.insert(0, \"t\", events.pop(\"TimeStamp\")/1000)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= []\n",
    "for n, grp in events.groupby(\"channel_name\"):\n",
    "    # print(grp)\n",
    "    if (grp[\"State\"]!=(np.arange(len(grp.index)) % 2)).any():\n",
    "        raise Exception(f\"State column problem for input {n}\")\n",
    "    if len(grp.index) % 2 ==0:\n",
    "      end = grp[\"t\"].iloc[1::2].to_numpy()\n",
    "    else:\n",
    "      end=np.pad(grp[\"t\"].iloc[1::2].to_numpy(), ((0, 1),), constant_values=np.nan)\n",
    "    new_df = pd.DataFrame(dict(\n",
    "       channel_name=n, \n",
    "       t=grp[\"t\"].iloc[::2].to_numpy(),\n",
    "       end=end,\n",
    "       original_index=grp[\"original_index\"].iloc[::2].to_numpy(),\n",
    "    ))\n",
    "    res.append(new_df)\n",
    "    \n",
    "events_df = pd.concat(res).sort_values([\"t\", \"original_index\"])\n",
    "events_df[\"duration\"] = events_df[\"end\"] - events_df[\"t\"]\n",
    "events_df = events_df.drop(columns=\"original_index\").reset_index(drop=True)\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for d in config[\"event_processing\"][\"new_events\"]:\n",
    "    if d[\"name\"] in events_df.columns:\n",
    "        raise Exception(f'Name {d[\"name\"]} already in use')\n",
    "    events_df[d[\"name\"]] = events_df.eval(d[\"filter\"], engine=\"python\")\n",
    "    cols.append(d[\"name\"])\n",
    "original_cols = [c for c in events_df.columns if not c in cols]\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[\"n_used\"] = events_df[cols].sum(axis=1)\n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"event_processing\"][\"on_unused\"] ==\"error\" and (events_df[\"n_used\"] ==0).any():\n",
    "    raise Exception(\"Some events where unused\")\n",
    "if config[\"event_processing\"][\"on_multiple\"] ==\"error\" and (events_df[\"n_used\"] > 1).any():\n",
    "    raise Exception(\"Some events where used several times\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = []\n",
    "for col in cols:\n",
    "    res_df.append(events_df[original_cols].loc[events_df[col]].assign(event=col))\n",
    "res_df = pd.concat(res_df).sort_values(\"t\").reset_index(drop=True)[[\"event\"]+original_cols].drop(columns=\"channel_name\")\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(\"events.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(params[\"fiber_data_path\"], skiprows=1)\n",
    "data[\"t\"] = data.pop(\"TimeStamp\")/1000\n",
    "data = data.dropna(axis=1, how=\"all\")\n",
    "data.columns = [c.replace(\"-\", \"_\") for c in data.columns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for item in config[\"signal_processing\"]:\n",
    "    name = item[\"name\"]\n",
    "    expr = item[\"expr\"]\n",
    "    if name in data.columns:\n",
    "        raise Exception(f'Name {name} already used...')\n",
    "    data[name] = data.eval(expr, engine=\"python\")\n",
    "    names.append(name)\n",
    "data = data[[\"t\"]+names]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing PSTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data.set_index(\"t\").to_xarray()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evs = res_df.to_xarray().rename_dims(index=\"ev\")\n",
    "evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = config[\"psth\"][\"window\"][\"bounds\"]\n",
    "fs = config[\"psth\"][\"window\"][\"t_fs\"]\n",
    "window_n = int((bounds[1] - bounds[0])*fs)\n",
    "window = xr.DataArray(np.arange(window_n)/fs + bounds[0], dims=\"window_t\")\n",
    "psth = d.interp(t=evs[\"t\"] + window)\n",
    "psth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbscripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
